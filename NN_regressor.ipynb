{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Ride Price using NeuralNet Regressor\n",
    "There are 5 parts in this notebook.\n",
    "\n",
    "0. Normalizate tne data\n",
    "1. Training on plaintext data\n",
    "2. Evaluate model on plaintext data\n",
    "3. Train and Quantize the Concrete model (Quantization Aware Training)\n",
    "4. Compile the model to the equivalent FHE circuit\n",
    "5. Evaluate the FHE model on encrypted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor as SklearnMLPRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from concrete.ml.sklearn import NeuralNetRegressor as ConcreteNNRegressor\n",
    "import torch\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset as panda's dataframe\n",
    "import pandas as pd\n",
    "taxi_dataset = pd.read_csv(\"./data/taxi_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        duration  price       tip  passengers  distance  hour_of_day  \\\n",
      "0       0.032663   5.80  0.000000    0.111111  0.018948     0.608696   \n",
      "1       0.109742  11.80  0.000000    0.222222  0.032249     0.478261   \n",
      "2       0.016614   5.30  0.000000    0.111111  0.012692     0.826087   \n",
      "3       0.018083   4.80  0.000000    0.111111  0.012637     0.347826   \n",
      "4       0.109516  24.36  0.020099    0.111111  0.167064     0.869565   \n",
      "...          ...    ...       ...         ...       ...          ...   \n",
      "485841  0.072107  13.80  0.009901    0.222222  0.078692     0.086957   \n",
      "485842  0.027125   7.56  0.006238    0.111111  0.028456     0.869565   \n",
      "485843  0.038766   7.55  0.006188    0.333333  0.025674     0.739130   \n",
      "485844  0.063630  11.75  0.009653    0.111111  0.037486     0.956522   \n",
      "485845  0.156533  15.80  0.000000    0.111111  0.043669     0.782609   \n",
      "\n",
      "        hour_of_week  day_of_week  start_location_id  end_location_id  \\\n",
      "0           0.658683     0.666667           0.714286         0.755102   \n",
      "1           0.209581     0.166667           0.571429         0.653061   \n",
      "2           0.113772     0.000000           0.571429         0.653061   \n",
      "3           0.191617     0.166667           0.714286         0.765306   \n",
      "4           0.550898     0.500000           0.571429         0.765306   \n",
      "...              ...          ...                ...              ...   \n",
      "485841      0.443114     0.500000           0.571429         0.653061   \n",
      "485842      0.694611     0.666667           0.714286         0.765306   \n",
      "485843      0.964072     1.000000           0.571429         0.653061   \n",
      "485844      0.275449     0.166667           0.571429         0.653061   \n",
      "485845      0.251497     0.166667           0.571429         0.653061   \n",
      "\n",
      "        start_longitude  start_latitude  end_longitude  end_latitude  payment  \\\n",
      "0              0.539221        0.696163       0.523394      0.777534      0.0   \n",
      "1              0.498765        0.487954       0.472558      0.630062      0.0   \n",
      "2              0.501628        0.568376       0.497927      0.675818      0.0   \n",
      "3              0.540007        0.635506       0.535944      0.738856      0.0   \n",
      "4              0.489176        0.481898       0.548221      0.731811      0.0   \n",
      "...                 ...             ...            ...           ...      ...   \n",
      "485841         0.460426        0.565958       0.500803      0.640598      0.0   \n",
      "485842         0.542990        0.643155       0.542177      0.755197      0.0   \n",
      "485843         0.474937        0.543341       0.456071      0.661523      0.0   \n",
      "485844         0.480662        0.483811       0.451304      0.629636      0.0   \n",
      "485845         0.522584        0.572213       0.488373      0.697606      0.0   \n",
      "\n",
      "        vendor   bearing  airport  \n",
      "0          1.0  0.305556      0.0  \n",
      "1          0.0  0.222222      0.0  \n",
      "2          1.0  0.027778      0.0  \n",
      "3          0.0  0.472222      0.0  \n",
      "4          1.0  0.555556      0.0  \n",
      "...        ...       ...      ...  \n",
      "485841     1.0  0.861111      0.0  \n",
      "485842     1.0  0.500000      0.0  \n",
      "485843     0.0  0.194444      0.0  \n",
      "485844     0.0  0.250000      0.0  \n",
      "485845     0.0  0.277778      0.0  \n",
      "\n",
      "[485846 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "columns_to_scale = taxi_dataset.columns.difference(['price'])\n",
    "\n",
    "taxi_dataset[columns_to_scale] = scaler.fit_transform(taxi_dataset[columns_to_scale])\n",
    "print(taxi_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConcreteMl currently does not support input or output data in categorical, string, or generic object data types\n",
    "# so let's convert the data type of the target array to integer\n",
    "# target = taxi_dataset.price.astype(\"int\")\n",
    "target = taxi_dataset.price\n",
    "\n",
    "# print(target)\n",
    "\n",
    "# split the inputs and targets into a train/test dataset\n",
    "# TODO: look up random_state parameter\n",
    "# split the dataset into 80% training data and 20% testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    taxi_dataset, target, test_size=0.4, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training on plaintext data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(activation=&#x27;identity&#x27;, alpha=1, hidden_layer_sizes=(25,),\n",
       "             learning_rate_init=0.005, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(activation=&#x27;identity&#x27;, alpha=1, hidden_layer_sizes=(25,),\n",
       "             learning_rate_init=0.005, max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(activation='identity', alpha=1, hidden_layer_sizes=(25,),\n",
       "             learning_rate_init=0.005, max_iter=1000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train sklearn MLPRegressor model on the clear\n",
    "sklearn_MLP_regressor = SklearnMLPRegressor(\n",
    "                    alpha=1,\n",
    "                    activation=\"identity\",\n",
    "                    max_iter=1000,\n",
    "                    hidden_layer_sizes=(25,),\n",
    "                    learning_rate_init=0.005,)\n",
    "sklearn_MLP_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluate model on plaintext data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.29941699 11.29950719 36.79874836 ... 11.61936247 24.79950316\n",
      " 12.95937163]\n",
      "Model evaluation time on the clear: 0.00000024 seconds per sample\n",
      "0.999999994683011\n"
     ]
    }
   ],
   "source": [
    "time_begin = time.time()\n",
    "y_pred = sklearn_MLP_regressor.predict(X_test)\n",
    "print(y_pred)\n",
    "execution_time_on_plaintext = (time.time() - time_begin) / len(X_test)\n",
    "print(f\"Model evaluation time on the clear: {execution_time_on_plaintext:.8f} seconds per sample\")\n",
    "# Compute the R2 scores\n",
    "sklearn_r2_score = r2_score(y_test, y_pred)\n",
    "print(sklearn_r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train and Quantize the Concrete model (Quantization Aware Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1       \u001b[36m11.7663\u001b[0m       \u001b[32m40.5754\u001b[0m  57.8481\n",
      "done training\n",
      "done prediction\n",
      "done calculating r2 score\n",
      "0.6659336746804537\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model with parameter\n",
    "# TODO: tune the parameter\n",
    "params_neural_net = {\n",
    "    # \"module__n_w_bits\": 6,\n",
    "    # \"module__n_a_bits\": 8,\n",
    "    # \"module__n_accum_bits\": 16,\n",
    "    \"module__n_hidden_neurons_multiplier\": 10,\n",
    "    \"module__n_layers\": 2,  # total number of layers in the FCNN = 1 hidden layer\n",
    "    \"module__activation_function\": torch.nn.ReLU,\n",
    "    \"max_epochs\": 1,\n",
    "    \"verbose\": 1,\n",
    "    # \"lr\": 0.1,\n",
    "}\n",
    "\n",
    "\n",
    "#some sort of Feature preprocessing needed for quantization aware training\n",
    "# Linear models require polynomial features to be applied before training to fit a non-linear model and other models perform better with this transoformation\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"poly\", PolynomialFeatures()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_poly_train = pipe.fit_transform(X_train)\n",
    "X_poly_test = pipe.transform(X_test)\n",
    "\n",
    "concrete_NN_regressor = ConcreteNNRegressor(batch_size=32, **params_neural_net)\n",
    "\n",
    "# train the concrete linear regression model on clear data\n",
    "# The built-in NN regressor models will automatically quantize weights and activations with .fit() call. (Quantization Aware Training) These models use several layers for Quantization Aware Training, allowing good performance for low precision (down to 2-3 bits) weights and activations.\n",
    "# The maximum accumulator bit-width is controlled by the number of weights and activation bits, as well as a pruning factor. This factor is automatically determined based on the desired accumulator bit-width and a multiplier factor can be optionally specified.\n",
    "\n",
    "\n",
    "concrete_NN_regressor.fit(X_poly_train, y_train.values.reshape(-1, 1))\n",
    "print(\"done training\")\n",
    "\n",
    "# Now, we can test our Concrete ML model on the clear test data\n",
    "y_pred_q = concrete_NN_regressor.predict(X_poly_test)\n",
    "print(\"done prediction\")\n",
    "# Compute the R2 scores\n",
    "quantized_r2_score = r2_score(y_test, y_pred_q)\n",
    "\n",
    "print(\"done calculating r2 score\")\n",
    "\n",
    "print(quantized_r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compile the model to the equivalent FHE circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating a key for a 12-bit circuit\n",
      "Compilation time: 248.9701 seconds\n",
      "Generating a key for a 12-bit circuit\n",
      "Key generation time: 154.4244 seconds\n"
     ]
    }
   ],
   "source": [
    "# Compile the quantized model in to FHE circuit and run inference on it\n",
    "# You have to provide the training dataset in order to compile the quantized model to equivalent FHE circuit\n",
    "time_begin = time.time()\n",
    "fhe_circuit = concrete_NN_regressor.compile(X_poly_train)\n",
    "print(f\"Generating a key for a {fhe_circuit.graph.maximum_integer_bit_width()}-bit circuit\")\n",
    "print(f\"Compilation time: {time.time() - time_begin:.4f} seconds\")\n",
    "\n",
    "# Compiler returns the circuit, which can be used to generated a secrete key and evaluation key\n",
    "# secrete key: used for encryption and decryption. only accesible to the client\n",
    "# evaluation key: used to evaluate the cirucit on encypted data. anyone can access it\n",
    "print(f\"Generating a key for a {fhe_circuit.graph.maximum_integer_bit_width()}-bit circuit\")\n",
    "\n",
    "time_begin = time.time()\n",
    "fhe_circuit.client.keygen(force=False)\n",
    "print(f\"Key generation time: {time.time() - time_begin:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the FHE model on encrypted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Evaluate the FHE-version of the model\n",
    "time_begin = time.time()\n",
    "y_pred_fhe = concrete_NN_regressor.predict(X_poly_test[:1], fhe=\"execute\")\n",
    "\n",
    "execution_time_on_ciphertext = (time.time() - time_begin) / len(X_test)\n",
    "print(f\"Execution time: {execution_time_on_ciphertext:.8f} seconds per sample\")\n",
    "print(f\"which is {(execution_time_on_ciphertext / execution_time_on_plaintext):.2f} times slower than prediction on the plaintext data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure R2 score of FHE version of the model\n",
    "fhe_r2_score = r2_score(y_test, y_pred_fhe)\n",
    "\n",
    "print(\"R^2 scores:\")\n",
    "print(f\"scikit-learn (clear): {sklearn_r2_score:.4f}\")\n",
    "print(f\"Concrete ML (quantized model on plaintext): {quantized_r2_score:.4f}\")\n",
    "print(f\"Concrete ML (FHE model on ciphertext): {fhe_r2_score:.4f}\")\n",
    "\n",
    "# Measure the error of the FHE quantized model with respect to the clear scikit-learn float model\n",
    "concrete_score_difference = abs(fhe_r2_score - quantized_r2_score) * 100 / quantized_r2_score\n",
    "print(\n",
    "    \"\\nRelative score difference for Concrete ML (quantized model on clear) vs. Concrete ML (FHE):\",\n",
    "    f\"{concrete_score_difference:.2f}%\",\n",
    ")\n",
    "\n",
    "# Measure the error of the FHE quantized model with respect to the clear float model\n",
    "score_difference = abs(fhe_r2_score - sklearn_r2_score) * 100 / sklearn_r2_score\n",
    "print(\n",
    "    \"Relative score difference for scikit-learn (clear) vs. Concrete ML (FHE) scores:\",\n",
    "    f\"{score_difference:.2f}%\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "concrete-arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
