{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Ride Price using NeuralNet Regressor\n",
    "There are 5 parts in this notebook.\n",
    "0. Normalizate tne data\n",
    "1. Training on plaintext data\n",
    "2. Evaluate model on plaintext data\n",
    "3. Train and Quantize the Concrete model (Quantization Aware Training)\n",
    "4. Compile the model to the equivalent FHE circuit\n",
    "5. Evaluate the FHE model on encrypted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/concrete-arm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import required packages\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor as SklearnMLPRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from concrete.ml.sklearn import NeuralNetRegressor as ConcreteNNRegressor\n",
    "import torch\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset as panda's dataframe\n",
    "import pandas as pd\n",
    "taxi_dataset = pd.read_csv(\"./data/taxi_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        duration  price   tip  passengers  distance  hour_of_day  \\\n",
      "0       0.032663   5.80  0.00           1  0.018948           14   \n",
      "1       0.109742  11.80  0.00           2  0.032249           11   \n",
      "2       0.016614   5.30  0.00           1  0.012692           19   \n",
      "3       0.018083   4.80  0.00           1  0.012637            8   \n",
      "4       0.109516  24.36  4.06           1  0.167064           20   \n",
      "...          ...    ...   ...         ...       ...          ...   \n",
      "485841  0.072107  13.80  2.00           2  0.078692            2   \n",
      "485842  0.027125   7.56  1.26           1  0.028456           20   \n",
      "485843  0.038766   7.55  1.25           3  0.025674           17   \n",
      "485844  0.063630  11.75  1.95           1  0.037486           22   \n",
      "485845  0.156533  15.80  0.00           1  0.043669           18   \n",
      "\n",
      "        hour_of_week  day_of_week  start_location_id  end_location_id  \\\n",
      "0                110            4                 75               74   \n",
      "1                 35            1                 64               64   \n",
      "2                 19            0                 64               64   \n",
      "3                 32            1                 75               75   \n",
      "4                 92            3                 64               75   \n",
      "...              ...          ...                ...              ...   \n",
      "485841            74            3                 64               64   \n",
      "485842           116            4                 75               75   \n",
      "485843           161            6                 64               64   \n",
      "485844            46            1                 64               64   \n",
      "485845            42            1                 64               64   \n",
      "\n",
      "        start_longitude  start_latitude  end_longitude  end_latitude  payment  \\\n",
      "0            -73.955330       40.799570     -73.963646     40.803196        0   \n",
      "1            -73.980560       40.724037     -73.996870     40.723866        0   \n",
      "2            -73.978775       40.753212     -73.980290     40.748480        0   \n",
      "3            -73.954840       40.777565     -73.955444     40.782390        0   \n",
      "4            -73.986540       40.721840     -73.947420     40.778600        0   \n",
      "...                 ...             ...            ...           ...      ...   \n",
      "485841       -74.004470       40.752335     -73.978410     40.729534        0   \n",
      "485842       -73.952980       40.780340     -73.951370     40.791180        0   \n",
      "485843       -73.995420       40.744130     -74.007645     40.740790        0   \n",
      "485844       -73.991850       40.722534     -74.010760     40.723637        0   \n",
      "485845       -73.965706       40.754604     -73.986534     40.760200        0   \n",
      "\n",
      "        vendor  bearing  airport  \n",
      "0            2       11        0  \n",
      "1            1        8        0  \n",
      "2            2        1        0  \n",
      "3            1       17        0  \n",
      "4            2       20        0  \n",
      "...        ...      ...      ...  \n",
      "485841       2       31        0  \n",
      "485842       2       18        0  \n",
      "485843       1        7        0  \n",
      "485844       1        9        0  \n",
      "485845       1       10        0  \n",
      "\n",
      "[485846 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "columns_to_scale = ['duration', 'distance']\n",
    "\n",
    "taxi_dataset[columns_to_scale] = scaler.fit_transform(taxi_dataset[columns_to_scale])\n",
    "print(taxi_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConcreteMl currently does not support input or output data in categorical, string, or generic object data types\n",
    "# so let's convert the data type of the target array to integer\n",
    "# target = taxi_dataset.price.astype(\"int\")\n",
    "target = taxi_dataset.price\n",
    "\n",
    "# print(target)\n",
    "\n",
    "# split the inputs and targets into a train/test dataset\n",
    "# TODO: look up random_state parameter\n",
    "# split the dataset into 80% training data and 20% testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    taxi_dataset, target, test_size=0.4, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training on plaintext data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(activation=&#x27;identity&#x27;, alpha=1, hidden_layer_sizes=(25,),\n",
       "             learning_rate_init=0.005, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(activation=&#x27;identity&#x27;, alpha=1, hidden_layer_sizes=(25,),\n",
       "             learning_rate_init=0.005, max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(activation='identity', alpha=1, hidden_layer_sizes=(25,),\n",
       "             learning_rate_init=0.005, max_iter=1000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train sklearn MLPRegressor model on the clear\n",
    "sklearn_MLP_regressor = SklearnMLPRegressor(\n",
    "                    alpha=1,\n",
    "                    activation=\"identity\",\n",
    "                    max_iter=1000,\n",
    "                    hidden_layer_sizes=(25,),\n",
    "                    learning_rate_init=0.005,)\n",
    "sklearn_MLP_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluate model on plaintext data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.33671147 11.32873063 36.85724788 ... 11.65661474 24.82754735\n",
      " 12.99360914]\n",
      "Model evaluation time on the clear: 0.00000028 seconds per sample\n",
      "0.9999885442843377\n"
     ]
    }
   ],
   "source": [
    "time_begin = time.time()\n",
    "y_pred = sklearn_MLP_regressor.predict(X_test)\n",
    "print(y_pred)\n",
    "execution_time_on_plaintext = (time.time() - time_begin) / len(X_test)\n",
    "print(f\"Model evaluation time on the clear: {execution_time_on_plaintext:.8f} seconds per sample\")\n",
    "# Compute the R2 scores\n",
    "sklearn_r2_score = r2_score(y_test, y_pred)\n",
    "print(sklearn_r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train and Quantize the Concrete model (Quantization Aware Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m7.4204\u001b[0m       \u001b[32m35.6695\u001b[0m  22.6032\n",
      "done training\n",
      "done prediction\n",
      "done calculating r2 scooooooooooooooooooooooooooooooooooooooore\n",
      "0.763408817057941\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model with parameter\n",
    "# TODO: tune the parameter\n",
    "params_neural_net = {\n",
    "    # \"module__n_w_bits\": 6,\n",
    "    # \"module__n_a_bits\": 8,\n",
    "    # \"module__n_accum_bits\": 16,\n",
    "    \"module__n_hidden_neurons_multiplier\": 10,\n",
    "    \"module__n_layers\": 2,  # total number of layers in the FCNN = 1 hidden layer\n",
    "    \"module__activation_function\": torch.nn.ReLU,\n",
    "    \"max_epochs\": 1,\n",
    "    \"verbose\": 1,\n",
    "    # \"lr\": 0.1,\n",
    "}\n",
    "\n",
    "\n",
    "#some sort of Feature preprocessing needed for quantization aware training\n",
    "# Linear models require polynomial features to be applied before training to fit a non-linear model and other models perform better with this transoformation\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"poly\", PolynomialFeatures()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_poly_train = pipe.fit_transform(X_train)\n",
    "X_poly_test = pipe.transform(X_test)\n",
    "\n",
    "concrete_NN_regressor = ConcreteNNRegressor(**params_neural_net)\n",
    "\n",
    "# train the concrete linear regression model on clear data\n",
    "# The built-in NN regressor models will automatically quantize weights and activations with .fit() call. (Quantization Aware Training) These models use several layers for Quantization Aware Training, allowing good performance for low precision (down to 2-3 bits) weights and activations.\n",
    "# The maximum accumulator bit-width is controlled by the number of weights and activation bits, as well as a pruning factor. This factor is automatically determined based on the desired accumulator bit-width and a multiplier factor can be optionally specified.\n",
    "\n",
    "\n",
    "concrete_NN_regressor.fit(X_poly_train, y_train.values.reshape(-1, 1))\n",
    "print(\"done training\")\n",
    "\n",
    "# Now, we can test our Concrete ML model on the clear test data\n",
    "y_pred_q = concrete_NN_regressor.predict(X_poly_test)\n",
    "print(\"done prediction\")\n",
    "# Compute the R2 scores\n",
    "quantized_r2_score = r2_score(y_test, y_pred_q)\n",
    "\n",
    "print(\"done calculating r2 scooooooooooooooooooooooooooooooooooooooore\")\n",
    "\n",
    "print(quantized_r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compile the model to the equivalent FHE circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating a key for a 12-bit circuit\n",
      "Compilation time: 273.5906 seconds\n",
      "Generating a key for a 12-bit circuit\n",
      "Key generation time: 5.0571 seconds\n"
     ]
    }
   ],
   "source": [
    "# Compile the quantized model in to FHE circuit and run inference on it\n",
    "# You have to provide the training dataset in order to compile the quantized model to equivalent FHE circuit\n",
    "time_begin = time.time()\n",
    "fhe_circuit = concrete_NN_regressor.compile(X_poly_train)\n",
    "print(f\"Generating a key for a {fhe_circuit.graph.maximum_integer_bit_width()}-bit circuit\")\n",
    "print(f\"Compilation time: {time.time() - time_begin:.4f} seconds\")\n",
    "\n",
    "# Compiler returns the circuit, which can be used to generated a secrete key and evaluation key\n",
    "# secrete key: used for encryption and decryption. only accesible to the client\n",
    "# evaluation key: used to evaluate the cirucit on encypted data. anyone can access it\n",
    "print(f\"Generating a key for a {fhe_circuit.graph.maximum_integer_bit_width()}-bit circuit\")\n",
    "\n",
    "time_begin = time.time()\n",
    "fhe_circuit.client.keygen(force=False)\n",
    "print(f\"Key generation time: {time.time() - time_begin:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the FHE model on encrypted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Evaluate the FHE-version of the model\n",
    "time_begin = time.time()\n",
    "y_pred_fhe = concrete_NN_regressor.predict(X_poly_test, fhe=\"execute\")\n",
    "\n",
    "execution_time_on_ciphertext = (time.time() - time_begin) / len(X_test)\n",
    "print(f\"Execution time: {execution_time_on_ciphertext:.8f} seconds per sample\")\n",
    "print(f\"which is {(execution_time_on_ciphertext / execution_time_on_plaintext):.2f} times slower than prediction on the plaintext data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 scores:\n",
      "scikit-learn (clear): 1.0000\n",
      "Concrete ML (quantized model on plaintext): 0.9982\n",
      "Concrete ML (FHE model on ciphertext): 0.9982\n",
      "\n",
      "Relative score difference for Concrete ML (quantized model on clear) vs. Concrete ML (FHE): 0.00%\n",
      "Relative score difference for scikit-learn (clear) vs. Concrete ML (FHE) scores: 0.18%\n"
     ]
    }
   ],
   "source": [
    "# Measure R2 score of FHE version of the model\n",
    "fhe_r2_score = r2_score(y_test, y_pred_fhe)\n",
    "\n",
    "print(\"R^2 scores:\")\n",
    "print(f\"scikit-learn (clear): {sklearn_r2_score:.4f}\")\n",
    "print(f\"Concrete ML (quantized model on plaintext): {quantized_r2_score:.4f}\")\n",
    "print(f\"Concrete ML (FHE model on ciphertext): {fhe_r2_score:.4f}\")\n",
    "\n",
    "# Measure the error of the FHE quantized model with respect to the clear scikit-learn float model\n",
    "concrete_score_difference = abs(fhe_r2_score - quantized_r2_score) * 100 / quantized_r2_score\n",
    "print(\n",
    "    \"\\nRelative score difference for Concrete ML (quantized model on clear) vs. Concrete ML (FHE):\",\n",
    "    f\"{concrete_score_difference:.2f}%\",\n",
    ")\n",
    "\n",
    "# Measure the error of the FHE quantized model with respect to the clear float model\n",
    "score_difference = abs(fhe_r2_score - sklearn_r2_score) * 100 / sklearn_r2_score\n",
    "print(\n",
    "    \"Relative score difference for scikit-learn (clear) vs. Concrete ML (FHE) scores:\",\n",
    "    f\"{score_difference:.2f}%\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "concrete-arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
